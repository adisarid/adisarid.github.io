[{"authors":null,"categories":null,"content":"Adi Sarid is a partner and head of Operations Research Department at the Sarid Research Institute LTD.\nAdi is completing his PhD in Operations Research at the department of Industrial Engineering in Tel-Aviv university. Adi holds an MSc in Operations Research from Tel-Aviv university, and a BA in Mathematics Statistics and Operations Research from the Technion.\nAdi is also a certified RStudio instructor, teaching tidyverse, shiny, statistics, and data science.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"f8818db5ae9279c4270c8f0d28984ccf","permalink":"/author/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/","section":"authors","summary":"Adi Sarid is a partner and head of Operations Research Department at the Sarid Research Institute LTD.\nAdi is completing his PhD in Operations Research at the department of Industrial Engineering in Tel-Aviv university.","tags":null,"title":"","type":"authors"},{"authors":null,"categories":["R"],"content":"\rCorona has put us in an awkward situation, where we must rethink and revise our ways of doing things (teaching, working, baby sitting, balancing work and life, or any other related field of your choosing). I also see this as an opportunity to experiment and improve various things. Specifically I dedicate this post to some teaching methods I have adopted. Mostly: using breakout rooms (a zoom feature) and learnr tutorials.\nThe challenges\rI teach an undergraduate course in introduction to statistics and data analysis with R, in Tel-Aviv university. The course involves statistical theory and practice with R. In general students found challenging to follow both theory and practice, and more so, considering that all lectures are conducted via zoom, due to Corona constraints.\nIn order to alleviate some of these challenges, I decided to split the lectures to theory and labs in smaller groups.\n\rMethodology\rlearnr is an R package which allows you to create an interactive html document (under the hood it’s based on RMarkdown and shiny). The result includes quizzes and chunks which can run R code. The chunks can come preloaded with some of the code and with hints/solutions.\nI teach a theoretical subject, and prepare a corresponding learnr tutorial on recent data sets from tidytuesday.\nDuring my lecture, I have specific checkpoints in which I split the zoom session into breakout rooms. Breakout rooms is a zoom feature which splits the main session into smaller sessions and allows the host to jump between the smaller sessions. I found that splitting the main room into groups of 3-4 participants which then together tackle the learnr tutorial is both fun and a fruitful experience. I cycle between the rooms to provide individual help for the groups. Every few minutes (10-15 minuts, depending on the tutorial section’s length and complexity), I merge the group back together to the main session, solve the tutorial section and either continue with theory or give them another section of the tutorial to work on in the smaller groups.\nEach tutorial includes important blocks of data analysis, sort of a “mini project” such as: data import, visualizations, data transformations, and modeling. I direct the blocks according to the topic I covered in the theoretical part.\nHere are two examples for tutorials I made, which went very well in class:\n\rFood consumption footprint with the source code here. This one is about getting to know your data, visualizations, descriptive statistics, confidence intervals and hypothesis tests for the expectancy of a distribution.\rVolcanos with the source code here. This one is about independence Chi square test, and also includes a lot of data preparations and visualizations. By the end of it, students test if volcano type and elevation are related (independent statistically or not).\r\r\rImportant notes\rThe first time you implement this, make sure the students understand how the zoom breakout feature works. Let them know you will be cycling through the rooms but that they can also use a ping/raise hand feature to call you.\nZoom comes with two options for assignment to breakout rooms: either random or manual (by host). Both are sub-optimal. Manually assigning 30 students to 10 breakout rooms will take too long and random ignores study groups the students already have. You can fine tune the random assignment, but that too takes too long. There is another option to upload a csv file with the participant’s names in advanced which is done via the settings of the meeting (on the zoom web page settings).\nWhen you setup the rooms, you have an option to set a time-limit. I found it sub-optimal, because you don’t always know in advanced how long the exercise will take. Instead cycling through the rooms should give you a good sense on when to merge back the breakout rooms into the main session.\nFor more help on using breakout rooms, follow this link from zoom’s support website.\n\rConclusions\rThis method, of using the zoom breakout rooms feature in combination with interactive learnr looks like a good formula for getting the students engaged while learning the necessary theoretical and practical aspects of data analysis.\nIf you are teaching interactively, I encourage you to give it a try! If you do, let me know how it went @SaridResearch on twitter.\n\r","date":1590491160,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1590491160,"objectID":"5779d9c22db36a8d8bf84d7ada307240","permalink":"/post/2020-05-26-break-rooms-and-learnr/","publishdate":"2020-05-26T11:06:00Z","relpermalink":"/post/2020-05-26-break-rooms-and-learnr/","section":"post","summary":"Corona has put us in an awkward situation, where we must rethink and revise our ways of doing things (teaching, working, baby sitting, balancing work and life, or any other related field of your choosing).","tags":["learnr"],"title":"Teaching with zoom breakout-rooms and the learnr package","type":"post"},{"authors":null,"categories":[],"content":"\rFor a while now I’ve been struggling with various installation setup related to the open source versions of RStudio server, Shiny server (and dockerized versions of them).\nAfter browsing internet tutorials on-and-off for the last couple of weeks I’ve come to the conclusion that there is a small gap when it comes to setting up RStudio server and shiny server securely, i.e., with SSL certificates.\nI’ve put together this step-by-step post to close this gap (in part for self-documentation). I don’t cover dockerized versions here.\nStep 1 (or actually steps 1-10)\rInstall rstudio server and shiny server on your choice of cloud provider. Common choices are AWS (EC2 or Lightsail, Digital Ocean, Azure, and Google. Anything works actually).\nInstallation instructions are covered in detail in Dean Attali’s post here which uses Digital Ocean.\nNo use repeating everything in its entirety. I will however highlight two things I’ve found helpful and are a bit different from Dean’s post.\nSelection of instance size (resources)\rAWS Lightsail’s deafult firewall settings\r\rSelection of instance size\rI’ve found that opening an instance with low memory (i.e., 0.5-1Gb) is problematic. Its cheap, but if you’re installing packages such as dplyr (included in tidyverse), compiling the package within your server, will require more memory than what you have available. You can workaround this by increasing your swap file size (step 6 in Dean’s post), but eventually even R processes might give you a hard time in the future. I’ve been using a 4GB server, which seems to be ok for my purposes (and at the time of writing this post costs about $20 USD per month).\n\rAWS Lightsail’s firewall settings\rWhen using AWS Lightsail (which I’ve been using), a default firewall rule is applied. This means that when you complete steps 7-8 in Dean’s post, your server will not work if you’re using AWS Lightsail. The reason for that is that AWS Lightsail built-in firewall blocks all ports except 22 and 80 by default (rstudio server uses 8787 and shiny server uses 3838). It doesn’t matter much, because by the end of this post we’ll be using port 443 (for secure SSL connection), but you can also make the non-secure version work out - useful for checking that your server is working. Let’s go ahead and open port 443 in your Lightsail instance (and explain how to also temporarily open 8787 and 3838).\nClick on the instance you’ve opened, and then go to the Networking tab. In this page you’ll see a “Firewall” title and beneath it a table with the currently open ports. Under the table click on “+ Add another”. Add HTTPS (under application), TCP (under protocol) and port 443, like in the following screenshot:\nIf you want to temporarily enable direct access to port 8787 and 3838 (to check that your installation went well), you can do that as well (use “Custom” under application, TCP for protocol, and port 8787 (repeat for 3838 in an additional line).\n\r\rSecure you server with SSL encryption\rSince you will probably be passing data back and forth between your remote server and local computer, you want to secure this data transfer with encryption. The best way to do this is using SSL certificates (it’s actually called TSL, the name SSL refers to a deprecated protocol, but everyone seems to still be using the SSL initials, see here).\nThere is a free service called Let’s Encrypt which provides SSL certificates, which is what we’re going to use here. I’m actually adopting the approach of this tutorial.\nInstall Let’s Encrypt and get certficates\rInstall the following software on your linux server\nsudo apt instal letsencrypt\rUpdate your nginx configuration as preperation for obtaining the let’s encrypt certificate. This step is needed because when requesting a certificate from let’s encrypt, the let’s encrypt server will try to authenticate your server.\nUse\nsudo nano /etc/nginx/sites-enabled/default\rAnd add the following (replace r.example.com with your domain):\nserver {\rlisten 80;\rlisten [::]:80;\rroot /var/www/r.example.com/html;\r# Add index.php to the list if you are using PHP\rindex index.html index.htm index.nginx-debian.html;\rserver_name r.example.com;\r}\rGet your SSL certificates using the following line, just replace r.example.com with your subdomain.\nletsencrypt certonly -a webroot --webroot-path=/var/www/r.example.com/html/ -d r.example.com\r\rUpdate your nginx settings again\nsudo nano /etc/nginx/sites-enabled/default\rTo have the following setup (remember to replace r.example.com with your domain):\nmap $http_upgrade $connection_upgrade {\rdefault upgrade;\r\u0026#39;\u0026#39; close;\r}\r# listens on port 80 and redirects traffic to secure alternative\rserver {\rlisten 80 default_server;\rlisten [::]:80 default_server;\rserver_name r.example.com;\rreturn 301 https://r.example.com$request_uri;\r}\rserver {\r# SSL configuration\rlisten 443 ssl;\rssl_certificate /etc/letsencrypt/live/r.example.com/fullchain.pem;\rssl_certificate_key /etc/letsencrypt/live/r.example.com/privkey.pem;\rssl_protocols TLSv1.2;\rssl_ciphers EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5;\rssl_prefer_server_ciphers On;\rssl_session_cache shared:SSL:128m;\radd_header Strict-Transport-Security \u0026quot;max-age=31557600; includeSubDomains\u0026quot;;\rssl_stapling on;\rssl_stapling_verify on;\rroot /var/www/r.example.com/html;\rserver_name _;\r# Reroute traffic to shiny server (i.e., reverse proxy for port 3838)\rlocation /shiny/ {\rproxy_pass http://127.0.0.1:3838/;\rproxy_http_version 1.1;\rproxy_set_header Upgrade $http_upgrade;\rproxy_set_header Connection $connection_upgrade;\rrewrite ^(/shiny/[^/]+)$ $1/ permanent;\r}\r# Reroute traffic to rstudio server (i.e., reverse proxy for port 8787)\rlocation /rstudio/ {\rproxy_pass http://127.0.0.1:8787/;\rproxy_http_version 1.1;\rproxy_set_header Upgrade $http_upgrade;\rproxy_set_header Connection $connection_upgrade;\r}\r}\r\rYour server should be working now, but since Let’s Encrypt certificates only last 90 days, lets put an automatically renewal process in place.\nsudo nano /opt/renewCerts.sh\rPaste the following text:\n#!/bin/sh\r# This script renews all the Let\u0026#39;s Encrypt certificates with a validity \u0026lt; 30 days\rif ! letsencrypt renew \u0026gt; /var/log/letsencrypt/renew.log 2\u0026gt;\u0026amp;1 ; then\recho Automated renewal failed:\rcat /var/log/letsencrypt/renew.log\rexit 1\rfi\rnginx -t \u0026amp;\u0026amp; nginx -s reload\rMake sure the script is owned and executable by root:\nchown root.root /opt/renewCerts.sh\rchmod u+x /opt/renewCerts.sh\rAdd it to cron for auto execution:\nsudo crontab -e\rAdd\n@weekly /opt/renewCerts.sh\r\r\rAll should be set!\rGo ahead and browse to your domain (e.g., https://r.example.com/rstudio). Check that you’re able to login properly and that all pages are secure on https.\n\r","date":1583532000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1583532000,"objectID":"9d527107842058e21b347763aa147fe3","permalink":"/post/2020-03-06-setup_rstudio_server_with_ssl/","publishdate":"2020-03-06T22:00:00Z","relpermalink":"/post/2020-03-06-setup_rstudio_server_with_ssl/","section":"post","summary":"For a while now I’ve been struggling with various installation setup related to the open source versions of RStudio server, Shiny server (and dockerized versions of them).\nAfter browsing internet tutorials on-and-off for the last couple of weeks I’ve come to the conclusion that there is a small gap when it comes to setting up RStudio server and shiny server securely, i.","tags":["RStudio server","nginx","Let's Encrypt"],"title":"Set up RStudio server with Let's Encrypt SSL certificate","type":"post"},{"authors":null,"categories":[],"content":"\rI’m just on my way back from this year’s rstudio::conf. Here’s an account of a few of the things which I found interesting, inspiring, or that might have some other impact in the future. I’m listing them by order of appearance in the conference.\nThe RMarkdown and Interactive Dashboards Workshop\rI participated as a TA in the RMarkdown and Interactive Dashboard workshop led by Carl Howe and Yihui Xie. The workshop dealt with creating RMarkdown documents. Specifically adding interactivity using the flexdashboard package to turn a simple docuement into an interactive html with just a few yaml configurations.\nSome attention was also given to combining different programming languages within documents, i.e. python via the reticulate package, but also css and many more.\nA lesser known feature (at least for me) was the crosstalk package which makes it really easy for different widgets in an RMarkdown document talk to each other.\nYihui talked about some cool tips and tricks and features of rmarkdown (and surrounding packages). For example:\n\rThe use of the xaringan::infinite_moon_reader() to continously render an Rmd upon save (automatically knits the document)\rCreating animation inside Rmds\rLaTeX tricks within Rmds\rCaching time consuming Rmd chunks\rMany more\r\rActually, these are just a few, and there were 23 distinct tips. Yihui’s presentation is available here. All the materials of this workshop, and in fact all the workshops, is available in this github repo.\nHere’s an example of an animation of a wave in an Rmd file. To replicate the example, use the following code in the chunk specifications: {r, animation.hook='gifski', fig.height=3, interval = 0.15}.\nlibrary(ggplot2)\rlibrary(tidyr)\rlibrary(dplyr)\rlibrary(purrr)\rdata_set \u0026lt;- crossing(frame = seq(0, 360, 30), x = seq(0, 2*pi, pi/10)) %\u0026gt;% mutate(y = sin(x - frame*pi/360)) %\u0026gt;% nest(data = c(x,y))\rmap(data_set$data, ~{\rggplot(., aes(x, y)) + geom_line()\r})\rCool, isn’t it?\nIf you’re into animations, there are other packages which can also accomplish this, such as the gganimate package.\n\rDeploying End-to-End Data Science with Shiny, Plumber, and Pins\rA nice talk by Alex Gold from RStudio. Showed a use case for a plumber api combined with a shiny app that talk to each other. For me, mainly the concept of pins as a quick approach for small to medium sized data sets was nice to see. You can easily put a data set in an S3 or any other means of storage on Azure, GCP, Github, etc. The downside compared to a database is that there is no frequent backup or an option to roll back changes.\n\rWe’re hitting R a million times a day so we made a talk about it\rA talk by Heather and Jacqueline Nolis from T-Mobile. This was kind of a follow-up talk on what they discussed in the previous rstudio::conf (2019), but this time they came with some important lessons from their in-field experiences.\nFor example, talking about garbage collection in R which happens once in a while and causes response times to lag. Can be avoided by manually calling the garbage collection with gc().\n\rAsynchronous programming in R\rWinston Chang demonstrating some ways for Asynchronous programming with the later package.\nAn interesting thing he Winston demonstrated was that you can open up a server using websocket and httpuv to interact with the R process even if the rstudio console is busy (i.e., for example during a shiny app run).\nMaterials of the talk will probably be available here https://github.com/wch/2020-01-later, though as of the time of writing these lines, the repo is empty. Maybe later.\n\rOf Teacups, Giraffes, \u0026amp; R Markdown\rA lovely and ispiring talk by Desiree De Lean, about how she (and a co-author) used a sort of Gamification to develop a statistics course. The course is based on the mysterious world of teacup Giraffes, and introduces statistical concepts with a nice and appealing twist.\nAnother innovative approach this used was to combine learnr iframes within the RMarkdown book they used, which makes the experience of the learner interactive. The learnr segments are hosted in turn on shinyapps.io.\nThe book is available online here.\n\rStyling Shiny apps with Saas and Bootstrap 4\rJoe Chang introduced the bootstraplibpackage which provides much more flexibilty when composing your own theme for a shiny app. It takes away a lot of the pains related with CSS-ing your way aound the complexities of a shiny app UI.\nThe package is still experimental, more info here.\nI talked to Joe Chang a bit, the package is not going to solve problems such as right-to-left localization for Hebrew.\n\r3D ggplots with rayshader\rA cool presentation by Tyler Morgan Wall author of the rayshader package. Demonstrated how ggplot2 charts can be easily rendered into a 3d model.\nMostly relevant for illustrating surfaces. The rayshader can be used to turn this plot:\nsurface \u0026lt;- crossing(x = seq(0, 2*pi, pi/20), y = seq(0, 2*pi, pi/20)) %\u0026gt;% mutate(z = sin(x)*x + cos(3*y))\rsurface_plot \u0026lt;- ggplot(surface, aes(x = x, y = y, fill = z)) + geom_tile()\rsurface_plot\rProjected as a 3d model using the rayshader here:\nrayshader::plot_gg(surface_plot)\rTyler also demonstrated how you can generate a movie with the camera browsing around the chart. Beware, rendering takes long.\n\rSummary\rObviously, there were many more notable talks at the conference, but this post was meant as a short list highlighting just a few.\nTo sum up, the rstudio conf, was a great opportunity to meet up with collegues (old and new), brush up on some of the advanced and noval packages, see how the rstudio team is planning and seeing the future of RStudio and of the R ecosystem, and enjoy San Fransisco!\n\r","date":1580486880,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580486880,"objectID":"613765b194701be693f1401cb31b61b9","permalink":"/post/2020-01-31-rstudio-conf2020-recap/","publishdate":"2020-01-31T06:08:00-10:00","relpermalink":"/post/2020-01-31-rstudio-conf2020-recap/","section":"post","summary":"I’m just on my way back from this year’s rstudio::conf. Here’s an account of a few of the things which I found interesting, inspiring, or that might have some other impact in the future.","tags":["rstudio conference"],"title":"Impressions and notes from rstudio::conf2020","type":"post"},{"authors":[],"categories":null,"content":"Presentation and source code are available here.\n","date":1579281000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1579281000,"objectID":"a0037003019d4d893066beae5cdcd87b","permalink":"/talk/plumber_api_meetup/","publishdate":"2020-01-17T19:10:00+02:00","relpermalink":"/talk/plumber_api_meetup/","section":"talk","summary":"Web APIs (RESTful APIs) are used everywhere to integrate various apps, across platforms and on the web. The way web APIs work is that by visiting some link with additional parameters appended to the link, you get a response, i.e., a json file, with meaningful results. In essense, the `plumber` package enables us, R developers, to share our code’s products as a web API. This is a good solution when you want to facilitate an easy integration for your clients, without having to expose your R code and your intellectual property. In my short talk, I will present what are web APIs, I will demonstrate how to calla web API with `httr` and finally explain the necessary steps to build up your own functional web api from the ground up.","tags":null,"title":"Want to talk to R? just call your plumber","type":"talk"},{"authors":null,"categories":["R"],"content":"\rThis semester I started teaching introduction to statistics and data analysis with R, at Tel-Aviv university.\nI put in a lot of efforts into bringing practical challenges, examples from real life, and a lot of demonstrations of statistical theory with R. This post is an example for how I’ve been using R code (and specifically Shiny apps) to demonstrate statistical theory, concepts and provide intuition.\nWhat’s the difference between confidence and prediction intervals?\rLast week I taught multiple linear regression, and I noticed that students have a hard time comprehending the difference between confidence intervals and prediction intervals. The former being an interval for the model (i.e., interval for the underlying model), and the latter being an interval for a noval observation.\nAs the sample size increases, our uncertainty of the model’s parameters decreases, but the uncertainty in the value of a new observation, \\(y_0\\) is associated with variance of \\(Y\\) (the random variable from which \\(y_0\\) is drawn). Hence, it has a lower bound, based on that variance.\nIn R, you can get a prediction or a confidence interval by using either\npredict(object, newdata, interval = \"prediction\")\nOr\npredict(object, newdata, interval = \"confidence\")\nFor a prediction or for a confidence interval, respectively.\nTo help me illustrate the differences between the two, I decided to build a small Shiny web app. It shows the differences between confidence intervals, prediction intervals, the regression fit, and the actual (original) model.\nThe app is available here, and the source code is available on github.\nWith this app you can choose three types of models to demonstrate. Simple linear regression, and regression with a twist (\\(\\log\\) transformation on the \\(y\\) or \\(\\sin\\) transformation on the \\(x\\):\n\rLinear model \\(y = a + bx + \\epsilon\\)\n\rLog-linear model \\(\\log(y)=a+bx+\\epsilon\\)\n\rSine \\(y = a + b\\sin(x) + \\epsilon\\)\n\r\rAll the models are based on simple linear regression (lm function), for the latter two models with either a log or sin transformation.\nThe app allows you to play around with various values such as the \\(x\\) range, the model’s parameters (\\(a\\) and \\(b\\)), the error’s standard deviation (\\(\\epsilon\\)), and show or hide any of the following elements, on the chart:\n\rThe original function (i.e., the original model)\n\rThe sampled points\n\rThe confidence interval\n\rThe prediction interval\n\rThe model’s fit\n\r\rFeel free to share the app or the app’s code. As mentioned above, the source code for the app is available here: https://github.com/adisarid/prediction_confidence_intervals_demo.\nHere’s an example for what the app’s generating code and output looks like, for a model of the type \\(\\log(y) = 1 + \\frac{x}{2} + \\epsilon\\):\nlibrary(dplyr)\rlibrary(tidyr)\rlibrary(tibble)\rlibrary(ggplot2)\rsample_size \u0026lt;- 90\rx_range \u0026lt;- c(0, 1.5)\ra \u0026lt;- 1\rb \u0026lt;- 1.5\rsigma \u0026lt;- 0.3\ractual_function \u0026lt;- tibble(x = seq(x_range[1], x_range[2], by = 0.01)) %\u0026gt;% mutate(actual_y = exp(a + b*x))\rrandom_sample \u0026lt;- tibble(epsilon_err = rnorm(n = sample_size, mean = 0,\rsd = sigma),\rx = runif(n = sample_size,\rmin = x_range[1],\rmax = x_range[2])) %\u0026gt;% mutate(sampled_y = exp(a + b*x + epsilon_err))\rlinear_model \u0026lt;- lm(formula = log(sampled_y) ~ x, data = random_sample)\rprediction_i \u0026lt;- predict(object = linear_model,\rnewdata = actual_function,\rinterval = \u0026quot;prediction\u0026quot;) %\u0026gt;% as_tibble() %\u0026gt;% rename_at(vars(lwr,upr), ~paste0(., \u0026quot;_pi\u0026quot;)) %\u0026gt;% mutate_all(exp)\rconfidence_i \u0026lt;- predict(object = linear_model,\rnewdata = actual_function,\rinterval = \u0026quot;confidence\u0026quot;) %\u0026gt;% as_tibble() %\u0026gt;% rename_at(vars(lwr,upr), ~paste0(., \u0026quot;_ci\u0026quot;)) %\u0026gt;% select(-fit) %\u0026gt;% mutate_all(exp)\rintervals \u0026lt;- actual_function %\u0026gt;% bind_cols(prediction_i,\rconfidence_i)\rggplot() + geom_line(data = actual_function, aes(x, actual_y, color = \u0026quot;Original Model\u0026quot;), size = 1) + geom_point(data = random_sample, aes(x, sampled_y), alpha = 0.5) + geom_line(data = intervals, aes(x, fit, color = \u0026quot;Regression Fit\u0026quot;), size = 1) + geom_line(data = intervals, aes(x, lwr_pi, color = \u0026quot;Prediction Interval\u0026quot;), linetype = 2, size = 1) +\rgeom_line(data = intervals, aes(x, upr_pi, color = \u0026quot;Prediction Interval\u0026quot;), linetype = 2, size = 1) + geom_line(data = intervals, aes(x, lwr_ci, color = \u0026quot;Confidence Interval\u0026quot;), linetype = 2, size = 1) + geom_line(data = intervals, aes(x, upr_ci, color = \u0026quot;Confidence Interval\u0026quot;), linetype = 2, size = 1) + theme_bw() + xlab(\u0026quot;x\u0026quot;) + ylab(\u0026quot;y\u0026quot;) + ggtitle(\u0026quot;Log-linear: Model, Fit, Confidence and Prediction Intervals\u0026quot;)\r\rConclusions\rShiny apps are a great way to illustrate theoretical concepts, to provide intuition, and to let students experiment with parameters and see the outcomes. In this post I demonstrated how a Shiny app can be used to explain the concepts of a regression fit, confidence, and prediction intervals.\nIf you used Shiny for interesting educational demonstrations I’d love to hear about it! feel free to share in the comments or message me on twitter @SaridResearch.\n\r","date":1576238400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576238400,"objectID":"70d819906bc1c287dc95c1bf14a45fc9","permalink":"/post/2019-12-13-confidence_prediction_intervals_explained/","publishdate":"2019-12-13T12:00:00Z","relpermalink":"/post/2019-12-13-confidence_prediction_intervals_explained/","section":"post","summary":"This semester I started teaching introduction to statistics and data analysis with R, at Tel-Aviv university.\nI put in a lot of efforts into bringing practical challenges, examples from real life, and a lot of demonstrations of statistical theory with R.","tags":["linear models","Shiny"],"title":"Confidence and prediction intervals explained... (with a Shiny app!)","type":"post"},{"authors":[],"categories":null,"content":"Presentation and source code are available here, accompanying shiny app used for demonstrations is available here.\n","date":1571933100,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571933100,"objectID":"1ae26b5c2d790ec908a653680b267e38","permalink":"/talk/not_so_shiny/","publishdate":"2019-10-24T18:05:00+02:00","relpermalink":"/talk/not_so_shiny/","section":"talk","summary":"Things that I learned about shiny app development, the \"hard way\". Talk given at a meetup held at the Microsoft Reactor, TLV.","tags":null,"title":"Not So Shiny?","type":"talk"},{"authors":null,"categories":["R"],"content":"\rGoogle drive is a great tool, specifically we’ve been using “G Suite” (the equivalent of google drive but for businesses), for a long time. Lately I noticed it’s missing an important feature - monitoring file shares and permission of google drive items across organization is non-trival (at least in the G suite basic subscription).\nI wanted to get a better sense of how my files and folders are shared across users within and outside the organization. I decided to give the googledrive package a try and extract the shares and permissions of important folders I had on my account. Here’s how I did that.\nUsing googledrive to mass extract shares and permission of google drive items\rFirst, I wanted to focus on specific folders which contain a lot of subfolders. My goal was to generate a tibble with the names of all sub-items (folder or files one level under the specific folders), along with all users which have access to these folders.\nHere is a description of what you need to do in order to accomplish what I described, followed by the code I used.\nGet the id (or URL) for the folder you want to retrieve data from. You can get the id by just visiting the folder, and the id is in the URL, i.e., https://drive.google.com/drive/u/1/folders/\u0026lt;HERE YOU WILL SEE THE FOLDER ID\u0026gt;.\rThen, retrieve all items within the folder.\rUse purrr functions (i.e., map and map_df to iterate over the results and bring them into a tidy form).\r(Optional) Use pivot_wider to create a tibble in a wide format where each row is an item and each column is the type of access each user has on the item.\r\rThe first function I’m using is a function I defined called get_permissions_df():\nlibrary(tidyverse)\rlibrary(googledrive) # the package used to iterface with the google api\r# Function to retrieve email addresses of permissions (read/write) --------\rget_permissions_df \u0026lt;- function(permission_list){\rmap_df(permission_list, ~{\rif (!is.null(.$emailAddress)){\rtibble(user_email = .$emailAddress, user_role = .$role)\r} else {\rtibble(user_email = NA, user_role = NA)\r}\r})\r}\rThe function returns a tibble with two columns: user_email and user_role, according to the users with access to the folder (access can be owner/writer/reader).\nNow, to actually pulling the data and processing it:\n# Read the contents of the folder -----\r# note that the first time you run this, you will be asked to login into your gmail using a web browser.\rfolder_contents \u0026lt;- drive_ls(as_id(\u0026quot;\u0026lt;FOLDER ID OR URL\u0026gt;\u0026quot;)) # replace here with the URL or ID of the folder.\r# Get a tidy form of all shares and permissions of subfolders\rtidy_permissions \u0026lt;- folder_contents %\u0026gt;% mutate(new_creds = map(drive_resource, ~{get_permissions_df(.$permissions)})\r) %\u0026gt;% select(name, new_creds) %\u0026gt;% unnest(new_creds) %\u0026gt;% filter(!is.na(user_email))\r# Optional - turn into a wider form where each column is a user,\r# each row is a subfolder, and values are permissions of users.\rwide_permissions \u0026lt;- tidy_permissions %\u0026gt;% distinct(name, user_email, .keep_all = T) %\u0026gt;% pivot_wider(id_cols = name, names_from = user_email, values_from = user_role, values_fill = list(user_role = \u0026quot;none\u0026quot;))\rThere you have it: tidy_permissions will hold the names of all subfolders with permissions. A folder will appear as many times as it has permissions (with the user email and the type of permission). The wide_permissions will hold a wide version in which each row is a folder and each column is a user.\nNote that this works for specific folders. You can also use drive_ls() without any arguments (or use it with recursive=TRUE), to pull everything on the drive (or everything within all subfolders, recursively). When I did that it took me around 5-10 minutes to pull all the data and about 5 minutes to prepare it, since I have \\(\u0026gt;100k\\) items.\n\rConclusions\rThe post provides a method to create a concise tibble with the contents of you google drive items, and their user permissions.\rYou can either run it on all items in your google drive or on selected folders (and sub-folders within). The method is especially useful in the context of data safety and security, when you want to make sure you are not sharing sensitive items in an undesired manner.\n\r","date":1568721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1568721600,"objectID":"35626b96f8c7e9b9481619de13716345","permalink":"/post/2019-09-17-google_drive_dir_structure_permissions/","publishdate":"2019-09-17T12:00:00Z","relpermalink":"/post/2019-09-17-google_drive_dir_structure_permissions/","section":"post","summary":"Google drive is a great tool, specifically we’ve been using “G Suite” (the equivalent of google drive but for businesses), for a long time. Lately I noticed it’s missing an important feature - monitoring file shares and permission of google drive items across organization is non-trival (at least in the G suite basic subscription).","tags":["googledrive"],"title":"Retrieving google drive item shares and permissions (in R)","type":"post"},{"authors":null,"categories":["R"],"content":"\rBackground\rShiny apps are a great way to share information and empower your users. Sometimes you want to make sure that only authenticated and authorized users will be able to view your shiny apps.\nThere are a number of ways to make sure only certain users have access to your apps. For example, you can subscribe to the professional plan in shinyapps.io which has this option built-in. You can program the authentication flow internally by yourself, or you just use a 3rd party service such as google firebase, AWS Cognito, Auth0, or others).\nThe benefit of using a dedicated service is that you get a lot of features which will be a serious headake to program yourself, such as social logins, two factor authentication, logs, and user blocks on suspicious attempts (or warnings on unauthorized attempts, depending on settings).\nThe down side is that it takes some time to implement. In this guide I aim to make the process as simple and painless as possible, using the Amazon Web Service’s authentication solution, called AWS Cognito. But first, some theory about authentication.\n\rHow authentication works\rThe logic behind authentication with AWS Cognito (or similar alternatives) is that you direct your users to a login page hosted by AWS, in which the user completes a process which confirms the user’s indentity. For example, by entering an e-mail and password, or by using a social sign-in (i.e., login via gmail, amazon, facebook). Then, once Cognito is finished, the user is redirected to your app with a URL variable which contain a specially issued code (i.e., https://your-app-address/?code=AMAZON_ISSUED_CODE.\nThen, you use an http request (i.e., with package httr) to query the Cognito API with this code, and in return you receive the information behind this code (i.e., the user’s token, with information such as the name of the user, what is the user’s email, validity of the token, etc.). This httr query is performed by using a password known only to you (i.e., only your app “knows” this password, this is not the user’s password).\nThe code is usable only once, and the token is valid for a limited duration, to minimize the risk that an unauthorized party will hijack the token and re-use it to access your app.\nAfter authenticating the user, you can authorize the user according to privileges (which you would have to manage within your app, i.e. if the users email is X, then he can view Y).\nThis process description was a very simplified, down-to-earth, nutshell description of oauth2. It might be inaccurate, but it will be enough for our goal here which is to actually implement it within a shiny app, integrating to Cognito. If you wish, you can find more information about oauth2 in detail here.\nLet’s get to business.\n\rStep 1: Define a user pool\rThis step is actually performed within the AWS Console. Log into your AWS console and find the Cognito service.\rClick on “Manage User Pools”, and then create a new user pool. The step-by-step wizard is pretty self explanatory, so I’ll focus on the important things:\n\rMake sure that you require a relevant field upon your user sign-up which you can “count on” in order to perform user authorization within your app based on that field later on. I usually check the email address as a required field, and then add logic in my app which maps email addresses to what each user is allowed to view.\rMulti-factor authentication can be “off”, “optional” or “required”. If your app contains sensitive information, then you should consider making it required.\r\rImportant! in the step where you are asked “Which app clients will have access to this user pool?” click on “Add an app client”. Give your app a name, the deafult options are sufficient so you shouldn’t change anything.\nMake sure you click on “Show Details” after you added your app and document the App client id and the App client secret. You will need them later on to interact with the Cognito API.\nOptional: right after you add your app and click “next step”, you will have a chance to add functions triggered by the various steps of the authentication flow. If you know what AWS Lambda functions are (and you defined such functions in your account) you can choose to trigger them depending on the authentication flow.\nComplete the wizard and create your user pool.\nEmail communications\rYou must have the AWS SES (simple email service) configured properly, in order for the registration of new users and “forgot password” flows to work. By default, SES is in sandbox mode, which means you can only register users with pre-verified emails. Defining SES is outside the scope of this guide, but note that you have to open a ticket in the AWS support center, asking for these privilleges.\nMake sure you supply AWS support with a lot of information about how you make sure emails don’t bounce, and about spam prevention. Even though it’s trivial, since this is an internal AWS system using the email service, they made me jump through hoops, untill granting me a 50k daily email cap, which is more than enough for me.\n\rApp client settings\rUnder the “App integration -\u0026gt; App client settings” you need to add the Callback URL of your app (where the user is directed upon login). For example, if your app is going to be hosted on shinyapps.io that would be: https://YOUR_USER_NAME.shinyapps.io/YOUR_APP_NAME. Your sign-out url can be the same, if you want the app to allow the user to restart the login, or a different page showing that the user has logged out.\nUnder OAuth 2.0/“Allowed OAuth Flows” you should check the: Authorization code grant. This is the authentication flow we are going to use for our shiny app. The “implicit grant” is not as secure, and the “client credentials” is used for machine-to-machine authentication.\nUnder “Allowed OAuth Scopes” check the options by which you are going to recognize your users within the shiny app’s logic. I.e., if you are going to show specific data by the user’s email address than make sure you check the “email” under allowed OAuth scopes.\nSet a domain name for your login screen and customize the UI of the login screen if you wish.\nYou can see in the following screenshot, that I’m using this authentication with one of my apps hosted in a shinyapps.io domain, under my account.\n\rEnable identity provides (Optional)\rIf you want to offer your users a social login such as Facebook or Google, you would need to issue the proper credentials via google console and facebook. This is a nice addition, but is out of the scope of this guide.\nFinally, we get into the R code part of this post.\n\r\rStep 2: Authorization code (within R)\rNow we need to add logic to our shiny app which will redirect the user to the AWS Cognito login page, and once the user authenticates and redirected to the shiny app, our shiny app will verify the token’s validity.\nVery basically, the Shiny app should read query url variables, and:\nIf no variables appear, show a login button to the user (which will redirect to the AWS Cognito login screen with the proper parameters).\rIf a url variable called code appears, our app will read its value, and use AWS Cognito to apply a second layer of verification and identification according to the code (read the token issued by Cognito).\rIf the user is logged on, show a “logout” button which will redirect the user into AWS Cognito logout link.\r\rRedirect links to login/logout screen (AUTHORIZATION, LOGOUT Endpoints)\rThere are two “endpoints” (urls) that your users will be redirected to:\nDuring their login flow into the app, or;\rAfter they click “logout”.\r\rThe first is the “AUTHORIZATION Endpoint”. It is a redirection of the client to a url of the following form (I have already put it into a paste0 command, which we will later use in our app).\nbase_cognito_url \u0026lt;- \u0026quot;https://YOUR_PREEDEFINED_AWS_COGNITO_DOMAIN.amazoncognito.com/\u0026quot;\rapp_client_id \u0026lt;- \u0026quot;YOUR_APP_CLIENT_ID\u0026quot;\rapp_client_secret \u0026lt;- \u0026quot;YOUR_APP_CLIENT_SECRET\u0026quot;\rredirect_uri \u0026lt;- \u0026quot;https://YOUR_APP/redirect_uri\u0026quot; # e.g., if you are using shinyapps.io this would be: # https://ACCOUNT_NAME.shinyapps.io/YOUR_APP_NAME\raws_auth_redirect \u0026lt;-\rpaste0(\rbase_cognito_url,\r\u0026quot;oauth2/authorize?\u0026quot;,\r\u0026quot;response_type=code\u0026amp;\u0026quot;,\r\u0026quot;client_id=\u0026quot;, app_client_id, \u0026quot;\u0026amp;\u0026quot;,\r\u0026quot;redirect_uri=\u0026quot;, redirect_uri, \u0026quot;\u0026amp;\u0026quot;,\r\u0026quot;state=appredirect\u0026quot;\r)\raws_auth_redirect\r## [1] \u0026quot;https://YOUR_PREEDEFINED_AWS_COGNITO_DOMAIN.amazoncognito.com/oauth2/authorize?response_type=code\u0026amp;client_id=YOUR_APP_CLIENT_ID\u0026amp;redirect_uri=https://YOUR_APP/redirect_uri\u0026amp;state=appredirect\u0026quot;\rYou can also specify the “scopes” (what information should Cognito hold for your next query, email, phone, etc.). If you don’t specify any scopes, all the information available on the user will be provided (see the next section of this post “Querying Cognito with the grant code”).\nThe second endpoint is the “LOGOUT Endpoint” which will logout the user. It is important to provide a logout button so that users can safely close your app, without worrying about other users in the same computer abusing their credentials.\naws_auth_logout \u0026lt;-\rpaste0(\rbase_cognito_url, \u0026quot;logout?\u0026quot;,\r\u0026quot;client_id=\u0026quot;, app_client_id, \u0026quot;\u0026amp;\u0026quot;,\r\u0026quot;logout_uri=\u0026quot;, redirect_uri\r)\raws_auth_logout\r## [1] \u0026quot;https://YOUR_PREEDEFINED_AWS_COGNITO_DOMAIN.amazoncognito.com/logout?client_id=YOUR_APP_CLIENT_ID\u0026amp;logout_uri=https://YOUR_APP/redirect_uri\u0026quot;\rOnce a user has completed the login process (via the authorization endpoint), he will be redirected to your app (the link you provided in the redirect_uri and in the Cognito setup at step 1). If the login is successful, the user will return with a url variable called code, i.e. https://YOUR_APP/redirect_uri?code=####-####-####-####. The next step will be to make sure that this code is indeed valid, and to check who is the user trying to access behind this code.\n\rQuerying Cognito with the grant code\rThis is a crucial part, in which we make sure that the user is indeed valid, and allowed to access your app. We’re going to use the httr package for that.\nLet’s assume we have already pulled the authorization code from the Shiny app’s url variables (we’re going to show how to do that in step 3).\nWe’re going to build a function which gets the code as an argument and provides the user’s information (or an error if the user is not authenticated or there was a different failure). I usually place this code in my global.r file, which is a part of the shiny app’s bundle (ui.r, server.r, global.r), and is used to define an environment variables and functions which will be availble to the shiny app. You can also place it at the begining of the server.r if you don’t want a global.r file. If you are using a single app.r just put it before the app itself.\nHere is the code that goes into your global.r file:\nbase_cognito_url \u0026lt;- \u0026quot;https://YOUR_DOMAIN.YOUR_AMAZON_REGION.amazoncognito.com/\u0026quot;\rapp_client_id \u0026lt;- \u0026quot;YOUR_APP_CLIENT_ID\u0026quot;\rapp_client_secret \u0026lt;- \u0026quot;YOUR_APP_CLIENT_SECRET\u0026quot;\rredirect_uri \u0026lt;- \u0026quot;https://YOUR_APP/redirect_uri\u0026quot;\rlibrary(httr)\rapp \u0026lt;- oauth_app(appname = \u0026quot;my_shiny_app\u0026quot;,\rkey = app_client_id,\rsecret = app_client_secret,\rredirect_uri = redirect_uri)\rcognito \u0026lt;- oauth_endpoint(authorize = \u0026quot;authorize\u0026quot;,\raccess = \u0026quot;token\u0026quot;,\rbase_url = paste0(base_cognito_url, \u0026quot;oauth2\u0026quot;))\rretrieve_user_data \u0026lt;- function(user_code){\rfailed_token \u0026lt;- FALSE\r# get the token\rtryCatch({token_res \u0026lt;- oauth2.0_access_token(endpoint = cognito,\rapp = app,\rcode = user_code,\ruser_params = list(client_id = app_client_id,\rgrant_type = \u0026quot;authorization_code\u0026quot;),\ruse_basic_auth = TRUE)},\rerror = function(e){failed_token \u0026lt;\u0026lt;- TRUE})\r# check result status, make sure token is valid and that the process did not fail\rif (failed_token) {\rreturn(NULL)\r}\r# The token did not fail, go ahead and use the token to retrieve user information\ruser_information \u0026lt;- GET(url = paste0(base_cognito_url, \u0026quot;oauth2/userInfo\u0026quot;), add_headers(Authorization = paste(\u0026quot;Bearer\u0026quot;, token_res$access_token)))\rreturn(content(user_information))\r}\r\r\rStep 3: define your Shiny app’s server.r and ui.r\rIn our shiny app, we need to pull the code and use the retrieve_user_data function we’ve just defined as part of our verification of the user. Here is the code we will use for this. This should go into the server.r file.\nlibrary(shiny)\rlibrary(shinyjs)\r# define a tibble of allwed users (this can also be read from a local file or from a database)\rallowed_users \u0026lt;- tibble(\ruser_email = c(\u0026quot;user1@example.com\u0026quot;,\r\u0026quot;user2@example.com\u0026quot;))\rfunction(input, output, session){\r# initialize authenticated reactive values ----\r# In addition to these three (auth, name, email)\r# you can add additional reactive values here, if you want them to be based on the user which logged on, e.g. privileges.\ruser \u0026lt;- reactiveValues(auth = FALSE, # is the user authenticated or not\rname = NULL, # user\u0026#39;s name as stored and returned by cognito\remail = NULL) # user\u0026#39;s email as stored and returned by cognito\r# get the url variables ----\robserve({\rquery \u0026lt;- parseQueryString(session$clientData$url_search)\rif (!(\u0026quot;code\u0026quot; %in% names(query))){\r# no code in the url variables means the user hasn\u0026#39;t logged in yet\rshowElement(\u0026quot;login\u0026quot;)\r} else {\rcurrent_user \u0026lt;- retrieve_user_data(query$code)\r# if an error occurred during login\rif (is.null(current_user)){\rhideElement(\u0026quot;login\u0026quot;)\rshowElement(\u0026quot;login_error_aws_flow\u0026quot;)\rshowElement(\u0026quot;submit_sign_out_div\u0026quot;)\ruser$auth \u0026lt;- FALSE\r} else {\r# check if user is in allowed user list\r# for more robustness, use stringr::str_to_lower to avoid case sensitivity\r# i.e., (str_to_lower(current_user$email) %in% str_to_lower(allowed_users$user_email))\rif (current_user$email %in% allowed_users$user_email){\rhideElement(\u0026quot;login\u0026quot;)\rshowElement(\u0026quot;login_confirmed\u0026quot;)\rshowElement(\u0026quot;submit_sign_out_div\u0026quot;)\ruser$auth \u0026lt;- TRUE\ruser$email \u0026lt;- current_user$email\ruser$name \u0026lt;- current_user$name\r# ==== User is valid, continue prep ====\r# show the welcome box with user name\routput$confirmed_login_name \u0026lt;-\rrenderText({\rpaste0(\u0026quot;Hi there!, \u0026quot;,\ruser$name)\r})\r# ==== Put additional login dependent steps here (e.g. db read from source) ====\r# ADD HERE YOUR REQUIRED LOGIC\r# I personally like to select the first tab for the user to see, i.e.:\rshowTab(\u0026quot;main_navigation\u0026quot;, \u0026quot;content_tab_id\u0026quot;, select = TRUE) # (see the next chunk for how this tab is defined in terms of ui elements)\r# ==== Finish loading and go to tab ====\r} else {\r# user not allowed. Only show sign-out, perhaps also show a login error message.\rhideElement(\u0026quot;login\u0026quot;)\rshowElement(\u0026quot;login_error_user\u0026quot;)\rshowElement(\u0026quot;submit_sign_out_div\u0026quot;)\r}\r}\r}\r})\r# This is where you will put your actual elements (the server side that is) ----\r# For example:\routput$some_plot \u0026lt;- renderPlot({\r# *** THIS IS EXTREMELY IMPORTANT!!! ***\rvalidate(need(user$auth, \u0026quot;No privileges to watch data. Please contact support.\u0026quot;))\r# since shinyjs is not safe for hiding content, make sure that any information is covered\r# by the validate(...) expression as was specified. # Rendered elements which were not preceded by a validate expression can be viewed in the html code (even if you use hideElement).\r# only if user is confirmed the information will render (a plot in this case)\rplot(cars)\r})\r}\r\rThe accompanying user interface (ui.r) will look like the following:\n\rlibrary(shiny)\rlibrary(shinyjs)\rfluidPage(\ruseShinyjs(), # to enable the show/hide of elements such as login and buttons\rhidden( # this is how the logout button will like:\rdiv(\rid = \u0026quot;submit_sign_out_div\u0026quot;,\ra(id = \u0026quot;submit_sign_out\u0026quot;,\r\u0026quot;logout\u0026quot;,\rhref = aws_auth_logout,\rstyle = \u0026quot;color: black; -webkit-appearance: button; -moz-appearance: button; appearance: button; text-decoration: none; background:#ff9999; position: absolute; top: 0px; left: 20px; z-index: 10000;\rpadding: 5px 10px 5px 10px;\u0026quot;\r)\r)\r),\rnavbarPage(\r\u0026quot;Cognito auth example\u0026quot;,\rid = \u0026quot;main_navigation\u0026quot;,\rtabPanel(\r\u0026quot;identification\u0026quot;,\rvalue = \u0026quot;login_tab_id\u0026quot;,\rh1(\u0026quot;Login\u0026quot;),\rdiv(\rid = \u0026quot;login\u0026quot;,\rp(\u0026quot;To login you must identify with a username and password\u0026quot;),\r# This defines a login button which upon click will redirect to the AWS Cognito login page\ra(id = \u0026quot;login_link\u0026quot;,\r\u0026quot;Click here to login\u0026quot;,\rhref = aws_auth_redirect,\rstyle = \u0026quot;color: black;\r-webkit-appearance: button;\r-moz-appearance: button;\rappearance: button;\rtext-decoration: none;\rbackground:#95c5ff;\rpadding: 5px 10px 5px 10px;\u0026quot;)\r),\rhidden(div(\rid = \u0026quot;login_error_aws_flow\u0026quot;,\rp(\u0026quot;An error has occurred.\u0026quot;),\rp(\u0026quot;Please contact support\u0026quot;)\r)),\rhidden(\rdiv(\rid = \u0026quot;login_confirmed\u0026quot;,\rh3(\u0026quot;User confirmed\u0026quot;),\rfluidRow(\rtextOutput(\u0026quot;confirmed_login_name\u0026quot;)),\rfluidRow(\rp(\u0026quot;Use the menu bar to navigate.\u0026quot;),\rp(\r\u0026quot;Don\u0026#39;t forget to logout when you want to close the system.\u0026quot;\r)\r)\r)\r),\r),\rtabPanel(\u0026quot;Your actual content\u0026quot;, value = \u0026quot;content_tab_id\u0026quot;,\rfluidRow(plotOutput(\u0026quot;some_plot\u0026quot;)))\r)\r)\r\r\rConclusions\rThe post contains essential things you need in order to get started with AWS Cognito authentication for your shiny apps.\nYou can extend this process to any authentication service (for example, digital ocean has a similar service to Cognito). There are some packages which implement the entire process for other services, like googleAuthR for a gmail login see this link.\nIf you found this post useful, let me know!, either in comments below, or twitter, or email.\nAs always, be careful of how you implement this process in your own apps, to make sure there are no security risks or loopholes. Also, DISCLAIMER: The information in this post is free, you can use this however like. Note that it is published with the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n\r","date":1567166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567166400,"objectID":"1e909287f0b95d10802216934b789d64","permalink":"/post/2019-08-10-cognito-shiny-authentication/","publishdate":"2019-08-30T12:00:00Z","relpermalink":"/post/2019-08-10-cognito-shiny-authentication/","section":"post","summary":"Background\rShiny apps are a great way to share information and empower your users. Sometimes you want to make sure that only authenticated and authorized users will be able to view your shiny apps.","tags":["Shiny","AWS","Cognito","Authentication"],"title":"Securing Shiny apps with AWS Cognito authentication","type":"post"},{"authors":null,"categories":["R"],"content":"\rI’ve been building R shiny apps for a while now, and ever since I started working with shiny, it has significantly increased the set of services I offer my clients.\nHere’s a documentations of some of the many lessons I learned in previous projects I did. Hopefully, others can avoid them in the future.\nBackground\rShiny is a really great tool that allows data scientists to communicate their analysis in an appealing and an effective way. However, as data scientists we are used to thinking about things a certain way. Our way of thinking, and our practices are different than these of a software developer or a DevOps.\nHere are some of things I learned along the path of my Shiny app developing experiences - some things that you should and should not do.\n\rDon’t skip the planning phase\rDo a mockup, research your implementation options.\nMockup\rDo a mockup, even if it’s just a piece of paper which took you 5 minutes to draw. It will be worth it.\nShiny is very tempting in the sense that once you understand the concept of reactive programming, you can go from idea to a full app in a few days work. Why invest time in preparing a mockup or planning, when you can just go ahead and do the actual thing?\nMy experience tells me that the app is much more successful in capturing the customer’s needs, when he’s a part of the technical planning phase (when you share your dillemas with the client). It sets expectations, frames what you can and can’t (or won’t) do for the customer, and enables you to find solutions together.\nAlso, when you’re looking at a mockup (even if it’s just a simple drawing or a non-interactive slide), it helps in the next stages of building the app’s UI.\nHere is an example of how a mockup would look like when I’m drawing it on a piece of paper. Note how I’ve already written down the purpose of some of the elements and their expeted element ids. It helps building the UI when you’re actually looking at one of these.\nExample for a mockup drawing\n\r\rResearch\rWhen you encounter a requirement you did not encounter before, and wondering about how to accomplish it, research.\n\rIs there more than a single way to accomplish what you’re trying?\rWhat are the pros and cons of each method?\r\rFor example, when I needed to show a table and incorporate data intake into the table, I was researching two options, one with the DataTable package (via the editable=TRUE argument) and the other is the rhandsontable package.\nBoth provide data editing, eventually I chose randsontable which had some limitations (e.g., slower rendering than DataTable, no search box), but provided more features out-of-the-box (e.g., data validation displaying factors as a list, checkboxes, etc.).\n\r\rBe sure you can live up to your promises\rThis is more of a broad issue (you can say its true for anything).\nIn my case, in the past I promised some clients I’ll provide “realtime” dashboards. However, as it turned out, I was reading from a csv data dump which provided the data with delays going up to 15-30 minutes.\nIn most projects I do, 15 minutes and realtime are pretty much equivalent from a practical standpoint, but in a specific project I did recently, I had a client which wanted to check the data as it was changing minute-by-minute.\nThis gap in expectations caused some confusion and dissappointment. We eventually learned from this, and in the future, when realtime is a requirement, we will use a better data source (i.e., data base instead of the delayed data dump).\n\rDon’t forget to plan your budget\rMake sure you consider all the elements you need for the project. Plan the budget accordingly, and understand the ramifications of scaling the app.\nFor example, if you’re using shinyapps.io, get familiar with the pricing packages, figure out what will you need to provide a good SLA (relative to the number of users of the app).\nSame goes for other cloud services, e.g., using a data base - how many users? how many connections? size of data base?\nIn most cloud providers you can also set up billing alerts which lets you know when something is exceeding a predetermined threshold.\nAll of these are very important when you’re building your quote, and obviously when going into production with your App.\n\rDon’t skip testing and staging on your way to production\rIn software development there are various levels of environments, starting from your desktop (“local”), through development server, integration, testing, staging/acceptance, and production. See Wikipedia’s Deployment environment entry.\nWhen building an app, make sure you go through these steps. Specifically relating to testing, staging, and production). What I found to be particularly useful is to upload the app twice (in two seperate locations/urls):\nDeploy as a beta app (client acceptance/demo) in which I demonstrate additional features and discuss them with the client, before incorporating them into production.\rDeploy as a production/live app.\r\rAs you iterate and improve the app, fix bugs, and add new features, you are also at the risk of breaking things. Thus, you should first update the beta app, share the new additions, and let the client experiment with the app. This way you can double check you didn’t break anything else.\nOnly when the client authorizes the corrections, redeploy the new app to the production.\n\rConclusions\rAs data scientists using Shiny, we’ve also become software developers. We’re developing not just for ourselves or for other useRs in our community.\nWith Shiny we’re building for end-users. We’re building customer facing apps, and we need to keep that in mind. We should make sure that we adopt and use best practices of software development.\n\r","date":1563537600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1563537600,"objectID":"8d10b47a62962dcb8ce6ad96e0cbfbaa","permalink":"/post/2019-07-03-shiny_app_lessons/","publishdate":"2019-07-19T12:00:00Z","relpermalink":"/post/2019-07-03-shiny_app_lessons/","section":"post","summary":"I’ve been building R shiny apps for a while now, and ever since I started working with shiny, it has significantly increased the set of services I offer my clients.","tags":["Shiny"],"title":"What NOT to do when building a shiny app (lessons learned the hard way)","type":"post"},{"authors":null,"categories":["R"],"content":"\rOver the last month I gave a tidyverse + intro to data science corporate training in a startup in Tel-Aviv. We had two groups (beginners and intermediates), and for the last assignment of the course I was aiming for a short quiz comprised of various topics which we covered during the course, such that can also be automated easily (i.e., multiple choice questions).\nI came up with the following quiz, which I thought would be nice to share here. I guess that experts should probably be able to complete this in a few minutes, intermediate/beginners would probably complete this by up to 30 minutes.\nExam instructions\rThe following exam contains 10 questions which spans across the different topics regaring tidyverse, and some analysis dilemmas. Each question has four options but only one correct answer. Each correct answer provides you with 10 points.\nYou can use any materials you want including but not limited to: cheat sheets, our course materials, stack overflow, package documentation, running code and seeing what it does.\n\rQuestion 1:\rWhen would you use an R markdown file (.Rmd) versus a script file (.R) to save your work?\nIf I want the relative position of the file retained (so that it is easier to load files from the same directory), I will use an .Rmd file, otherwise I will use a .R file.\rWhen I want a complete documentation of my work in a report I will use a .Rmd. I will use a .R file for debugging and sourcing functions.\rThere is no significant difference between the two formats, and they can be used for the same things interchangably.\rThere is no benefit to using .R script files, the .Rmd format is always superior.\r\r\rQuestion 2:\rLook at the following segments of code.\n# segment 1:\rnew_data \u0026lt;- read.csv(\u0026quot;myfilename.csv\u0026quot;)\r# segment 2:\rnew_data %\u0026gt;% group_by(some_cool_suff) %\u0026gt;% summarize(average = mean(avg_me, na.rm = T)) -\u0026gt; updated_df\r# segment 3:\ravg_var \u0026lt;- mean(new_data$avg_me[!is.na(some_cool_stuff)], na.rm = T)\r# segment 4:\rdata.frame(a = 1:10, b = letters[1:10]) %\u0026gt;% sample_n(3)\r\rWhich segments would you classify as tidyverse syntax?\r(tidyverse syntax = code which uses functions from tidyverse packages, in which there is no function that you can replace to a tidyverse equivalent)\nSegment 1 and segment 3.\rSegment 2 and segment 4.\rSegment 4.\rSegment 2.\r\r\rQuestion 3:\rWhat ggplot2 geoms would you use to generate the following charts?\nFigure 1: not generated with ggplot2, Figure 2: geom_point.\rFigure 1: geom_boxplot, Figure 2: geom_line.\rFigure 1: geom_violin, Figure 2: geom_point.\rFigure 1: geom_boxplot, Figure 2: geom_point + geom_line.\r\r\rQuestion 4:\rWhat is the difference between the matrix and the tibble in the following?\nmatrix(cbind(1:10, letters[1:10], LETTERS[1:10]), ncol = 3)\r## [,1] [,2] [,3]\r## [1,] \u0026quot;1\u0026quot; \u0026quot;a\u0026quot; \u0026quot;A\u0026quot; ## [2,] \u0026quot;2\u0026quot; \u0026quot;b\u0026quot; \u0026quot;B\u0026quot; ## [3,] \u0026quot;3\u0026quot; \u0026quot;c\u0026quot; \u0026quot;C\u0026quot; ## [4,] \u0026quot;4\u0026quot; \u0026quot;d\u0026quot; \u0026quot;D\u0026quot; ## [5,] \u0026quot;5\u0026quot; \u0026quot;e\u0026quot; \u0026quot;E\u0026quot; ## [6,] \u0026quot;6\u0026quot; \u0026quot;f\u0026quot; \u0026quot;F\u0026quot; ## [7,] \u0026quot;7\u0026quot; \u0026quot;g\u0026quot; \u0026quot;G\u0026quot; ## [8,] \u0026quot;8\u0026quot; \u0026quot;h\u0026quot; \u0026quot;H\u0026quot; ## [9,] \u0026quot;9\u0026quot; \u0026quot;i\u0026quot; \u0026quot;I\u0026quot; ## [10,] \u0026quot;10\u0026quot; \u0026quot;j\u0026quot; \u0026quot;J\u0026quot;\rtibble(num = 1:10, sl = letters[1:10], cl = LETTERS[1:10])\r## # A tibble: 10 x 3\r## num sl cl ## \u0026lt;int\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt;\r## 1 1 a A ## 2 2 b B ## 3 3 c C ## 4 4 d D ## 5 5 e E ## 6 6 f F ## 7 7 g G ## 8 8 h H ## 9 9 i I ## 10 10 j J\rThe tibble has named variables (columns) and the matrix does not name the columns.\rThe tibble retains the original data type and the matrix converts the data types.\rmatrix is a base R function and tibble is a tidyverse function.\rAll of the above.\r\r\rQuestion 5:\rWhat stringr function would you use to simplify the following code?\nsome_string \u0026lt;- c(\u0026quot;How are you today?\u0026quot;, \u0026quot;Is this test ok?\u0026quot;, \u0026quot;You\u0026#39;re already half way in!\u0026quot;)\rmap_chr(some_string, ~paste0(stringi::stri_wrap(., width = 5), collapse = \u0026quot;\\n\u0026quot;))\rstr_count.\rstr_wrap.\rstr_sub.\rNo such function: must use a combination of a stringr and a loop (or a map function).\r\r\rQuestion 6:\rWhat is the difference between contains and one_of?\nBoth are “select helpers”, one_of is used to specify strings which starts with one of the specified expressions, and contains lets you specify the variable names in “non standard evaluation” (unquoted) style.\rcontains selects variables based on the regular expression you feed as an argument. one_of needs you to specify the variable names as strings.\rcontains selects variables which contain the literal string you feed into it. one_of needs you to specify the variables names as strings.\rBoth functions do the same thing with the same arguments.\r\r\rQuestion 7:\rWhen reshaping data with the gather function, what is the meaning of the ... argument?\nSpecify which variables to gather by.\rSpecify which variables not to gather by (using the “-” sign).\rSpecify either a or b.\rProvide variable by which to group the resulting tibble.\r\r\rQuestion 8:\rWhat function would you use to get all the rows in tibble1 which are not in tibble2?\nsetdiff(tibble1, tibble2)\rsetdiff(tibble2, tibble1)\rintersect(tibble1, tibble2)\rsemi_join(tibble1, tibble2)\r\r\rQuestion 9:\rAssume you examine the data which appears in the following scatter plot using per-axis boxplots. Would classify point A as an outlier?\nYes, only accoring to the y-axis.\rYes, only according to the x-axis.\rYes, according to either x-axis or y-axis.\rNo, it will not be classified as an outlier.\r\r\rQuestion 10:\rYou encountered a data set in which all variables are normally distributed with an unequal variance and\runequal expectancy (mean). You wish to run a KMeans clustering to cluster the data. What would you do\ras a preprocessing step?\nScale and center the data using the function scale.\rScale and center the data using min-max scaling and centering.\rEither a or b.\rNothing - since the data is already normally distributed, no scaling or centering is required.\r\r\rBonus question (5 points bonus):\rDid you sign up for R-Bloggers updates? (feed to receive R related news and updates)\nYes (5 points bonus).\rNo, but I’m doing it now (2.5 points bonus).\rNo, and I don’t intend to.\r\rP.S. I’m not getting any benefits from R-bloggers for “advertising” them, I genuinly think it’s a great source to stay updated, and improve your R capabilities.\n\rQuiz answers\rAnswers available in the following gist.\n\r","date":1556452800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556452800,"objectID":"020dbfb01905c730d5ee58584a07dfe6","permalink":"/post/2019-04-28-test_your_tidyness/","publishdate":"2019-04-28T12:00:00Z","relpermalink":"/post/2019-04-28-test_your_tidyness/","section":"post","summary":"Over the last month I gave a tidyverse + intro to data science corporate training in a startup in Tel-Aviv. We had two groups (beginners and intermediates), and for the last assignment of the course I was aiming for a short quiz comprised of various topics which we covered during the course, such that can also be automated easily (i.","tags":["Tidyverse"],"title":"Test your tidyness - a short quiz to check your tidyverse capabilities","type":"post"},{"authors":["admin"],"categories":null,"content":"\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1554595200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1554595200,"objectID":"557dc08fd4b672a0c08e0a8cf0c9ff7d","permalink":"/publication/preprint/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/preprint/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example preprint / working paper","type":"publication"},{"authors":null,"categories":["R"],"content":"\rA few months ago I attended the 2019 rstudio::conf, including the shiny train-the-trainer workshop. It was a two day workshop and it inspired me in many ways. The first day of the workshop focused on the very basics of teaching (R or anything else), and for me it put the spotlight on things I never considered before.\nOne of the important takeways from the workshop was how to approach educating others: preparing for a course, things you can do during the lessons, and how to self-learn and improve my own teaching methods afterwards.\nThis led me to create the teachR’s cheatsheet. It outlines the basics of teaching and I chose to give it the flavour of R (in the examples and illustrations within the cheatsheet).\nI have contributed it to RStudio’s cheat sheet repo, so you can download it directly from: https://github.com/rstudio/cheatsheets/raw/master/teachR.pdf.\nIn the cheat sheet you will find three segments:\nPreparing a new course / workshop / lesson.\rThings you can do during the lesson itself.\rThings you should do when the course is completed in order to improve your own teaching methods.\r\rI previously blogged about some of the things learned at the train-the-trainer, and not everything made it to the cheat sheet, so if you’re interested you can read more here.\nHere’s an example for some of the things you can find in the cheat sheet.\nDesigning a new course\rThe cheat sheet covers the various steps of designing a course, i.e.:\nPersona analysis of your learners.\rDefining the course’s goals using Bloom’s taxonomy.\rUsing conceptual maps to grasp what the the course should look like and what related terms/materials should appear.\rWriting the final exam, the slides, check-ins and faded examples.\r\rHere are some examples relating to 1-2:\nPersona analysis\rTake a while to understand and characterize your learners: are the novice? advanced? false experts?\nWhat are the learner’s goals from the course? what prior knowledge you can assume (and what not), and do they have any special needs.\nIf end up with too many personas anticipate trouble - it’s hard to accomodate a diverse crowd, what are you going to miss out on?\n\rDefine goals using Bloom’s taxonomy\rBloom’s taxonomy illustrates the levels of learning new concepts or topics.\nThe Vanderbilt University Center for Teaching has a nice illustration for it.\nBlooms Taxonomy\n\rYou can visit the Vanderbilt website for a more thorough explanation about the taxonomy, but suffice it to say that “remember” is the most basic form of acquired knowledge, and the highest levels (at the top of the pyramid) are evaluate and create (being able to evaluate someone else’s work, or create your own noval work).\nIf we translate that to R, “remember” might translate to: “learners will be able to state the main packages in tidyverse and their purpose” versus “create” which in that context would translate to: “learners will be able to contribute to a tidyverse packages or create their own tidy package.” You can see that the first is something you can teach an R beginner but the latter is much more complex and can be mastered by an advanced useR.\nWorking with Bloom’s taxonomy can help you set your goals for the course and also help you set the expectations with the learners of your course.\n\r\rDuring the course\rSome tips I learned at the train-the-trainer workshop, for when you are during the lesson itself.\nSticky notes\rAt the start of the lesson, give each learner three sticky notes (green, red, and blue).\rThe learners put them on their computers according to their progress:\n\rGreen = I’m doing fine / finished teh exercise.\rRed = Something is wrong, I need help.\rBlue = I need a break\r\rIf you see a lot of greens - try to up the pace. If you see a lot of reds, maybe take it easier.\n\rCheck-ins\rTry to set a few check-ins every hour, to evaluate the progress and make sure that the learners are “with you”. You can even use some kind of online surveying tool to turn this into a “game”.\n\r\rAfter the course\rMake sure you debrief properly, and learn from your experience. Use surveys to collect feedback. Also measure the time each chapter really takes you, so you can better estimate the time for each type of lesson.\n\rConclusion\rTeaching can be challenging, but it is also rewarding and fun.\nIt is important to come well prepared, and this cheat sheet can help you checklist what you need to do:\rhttps://github.com/rstudio/cheatsheets/raw/master/teachR.pdf\nTeaching is an iterative process in which you can keep improving each time, if you measure and learn from your mistakes.\n\r","date":1552392000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552392000,"objectID":"f3020499e5b9473f9ae7cd815a42bb13","permalink":"/post/2019-03-12-the_teachr_cheat_sheet/","publishdate":"2019-03-12T12:00:00Z","relpermalink":"/post/2019-03-12-the_teachr_cheat_sheet/","section":"post","summary":"A few months ago I attended the 2019 rstudio::conf, including the shiny train-the-trainer workshop. It was a two day workshop and it inspired me in many ways. The first day of the workshop focused on the very basics of teaching (R or anything else), and for me it put the spotlight on things I never considered before.","tags":["Train the Trainer","Teaching"],"title":"The teachR's::cheat sheet","type":"post"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Academic \rAcademic | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click \rPDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view \r  Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/img/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? \rAsk\n\rDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Academic's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":["R"],"content":"\rA few days ago I presented at the 9th Israeli class action lawsuit conference. You’re probably asking yourself what would a data scientist do in a room full of lawyers?\nApparently, there is a lot to do… Here’s the story: being in market research, we get a lot of lawyers which are faced with class action lawsuits (either suing or being sued) - and they hire us to conduct research and estimate things like the size of the group for the class action, or the total damages applied on the group.\nThis time, we did something special. we conducted our own survey, with consumers in the general public in Israel. The goal was to rate various ways of getting compensation (after settling a class action lawsuit).\nFor that we used conjoint analysis. Conjoint is where you ask the survey participants a set of questions (five in our case). Each question has a number of alternatives (or packages) to choose from, and these are randomized per respondent. In our case we showed three packages, each package is defined by three parameters relating to how a consumer can get compensation in case of a class action being won:\nPush versus pull - do you have to ask for the compensation or would you get the notification/compensation without asking.\rThe value of the compensation - tested at 4 levels (25, 50, 75, and 100 ILS)\rThe method of delivery - as a complimentary product, a refund at next purchase, bank cheque, or credit card.\r\rThe thing about conjoint analysis is that when you diversify enough, you can then run various models to estimate the weight of each parameter, i.e., using logistic regression.\nThe data is available in the github repo, and the specific data is under the data folder.\n#library(tidyverse)\rclass_action_conjoint \u0026lt;- read_csv(\u0026quot;https://raw.githubusercontent.com/adisarid/class-action-IL-survey/master/data/20190130020529-SurveyExport-general_public-conjoint.csv\u0026quot;,\rskip = 1,\rcol_names = c(\u0026quot;Response ID\u0026quot;, \u0026quot;Set Number\u0026quot;, \u0026quot;Card Number\u0026quot;, \u0026quot;compensation_push_pull\u0026quot;, \u0026quot;compensation_amount_ILS\u0026quot;, \u0026quot;compensation_type\u0026quot;,\r\u0026quot;score_selection\u0026quot;))\r## Parsed with column specification:\r## cols(\r## `Response ID` = col_double(),\r## `Set Number` = col_double(),\r## `Card Number` = col_double(),\r## compensation_push_pull = col_character(),\r## compensation_amount_ILS = col_double(),\r## compensation_type = col_character(),\r## score_selection = col_double()\r## )\rglimpse(class_action_conjoint)\r## Observations: 7,020\r## Variables: 7\r## $ `Response ID` \u0026lt;dbl\u0026gt; 10, 10, 10, 10, 10, 10, 10, 10, 10, 10...\r## $ `Set Number` \u0026lt;dbl\u0026gt; 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5,...\r## $ `Card Number` \u0026lt;dbl\u0026gt; 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1,...\r## $ compensation_push_pull \u0026lt;chr\u0026gt; \u0026quot;push\u0026quot;, \u0026quot;push\u0026quot;, \u0026quot;push\u0026quot;, \u0026quot;push\u0026quot;, \u0026quot;pull\u0026quot;...\r## $ compensation_amount_ILS \u0026lt;dbl\u0026gt; 75, 50, 25, 100, 25, 100, 75, 100, 50,...\r## $ compensation_type \u0026lt;chr\u0026gt; \u0026quot;another_product\u0026quot;, \u0026quot;credit_cart\u0026quot;, \u0026quot;ban...\r## $ score_selection \u0026lt;dbl\u0026gt; 0, 0, 100, 0, 100, 0, 0, 0, 100, 0, 10...\rclass_action_conjoint %\u0026gt;% count(compensation_push_pull)\r## # A tibble: 2 x 2\r## compensation_push_pull n\r## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt;\r## 1 pull 3516\r## 2 push 3504\rclass_action_conjoint %\u0026gt;% count(compensation_amount_ILS)\r## # A tibble: 4 x 2\r## compensation_amount_ILS n\r## \u0026lt;dbl\u0026gt; \u0026lt;int\u0026gt;\r## 1 25 1759\r## 2 50 1761\r## 3 75 1752\r## 4 100 1748\rclass_action_conjoint %\u0026gt;% count(compensation_type)\r## # A tibble: 5 x 2\r## compensation_type n\r## \u0026lt;chr\u0026gt; \u0026lt;int\u0026gt;\r## 1 another_product 1391\r## 2 bank_cheque 1410\r## 3 coupon 1403\r## 4 credit_cart 1415\r## 5 refund_next_purchase 1401\rYou can see that the different options are balanced (they should be - they were selected randomly) and that the number of observations is \\(7,020\\). This is because we had \\(n=468\\) respondents answering the conjoint question groups, each selecting best one out of three, with five such random sets (\\(5*3*468=7020\\)).\nLogistic regression\rThe easiest (and most basic) way to start analyzing the conjoint data is with logistic regression. Note that I’m not endorsing this use of logistic regression in conjoint analysis, because nowadays it has become a standard to compensate for mixed effects (see package lme4). However, for the purposes of this post, I’m going to carry on with the simple glm which is sufficiently good for our illustration. In any case, my experience is that the models yield similar results in most cases.\nglm_set \u0026lt;- class_action_conjoint %\u0026gt;% mutate(score_selection = score_selection/100) %\u0026gt;% mutate(compensation_push_pull = factor(compensation_push_pull,\rlevels = c(\u0026quot;pull\u0026quot;, \u0026quot;push\u0026quot;),\rordered = F),\rcompensation_type = factor(compensation_type,\rlevels = c(\u0026quot;another_product\u0026quot;,\r\u0026quot;refund_next_purchase\u0026quot;,\r\u0026quot;coupon\u0026quot;,\r\u0026quot;bank_cheque\u0026quot;,\r\u0026quot;credit_cart\u0026quot;),\rordered = F)) %\u0026gt;% select(-`Set Number`, -`Card Number`, -`Response ID`) %\u0026gt;% mutate(compensation_amount_ILS = factor(compensation_amount_ILS, levels = c(25, 50, 75, 100)))\rconjoint_glm_model \u0026lt;- glm(data = glm_set %\u0026gt;% select(score_selection, compensation_push_pull, compensation_amount_ILS, compensation_type),\rformula = score_selection ~ .,\rfamily = binomial())\rsummary(conjoint_glm_model)\r## ## Call:\r## glm(formula = score_selection ~ ., family = binomial(), data = glm_set %\u0026gt;% ## select(score_selection, compensation_push_pull, compensation_amount_ILS, ## compensation_type))\r## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -1.8635 -0.8111 -0.5139 0.8796 2.6557 ## ## Coefficients:\r## Estimate Std. Error z value Pr(\u0026gt;|z|)\r## (Intercept) -3.49667 0.11341 -30.832 \u0026lt;2e-16\r## compensation_push_pullpush 0.74140 0.05807 12.767 \u0026lt;2e-16\r## compensation_amount_ILS50 1.01476 0.09385 10.813 \u0026lt;2e-16\r## compensation_amount_ILS75 1.73623 0.09224 18.823 \u0026lt;2e-16\r## compensation_amount_ILS100 2.40149 0.09281 25.876 \u0026lt;2e-16\r## compensation_typerefund_next_purchase 0.08431 0.10399 0.811 0.418\r## compensation_typecoupon 1.10396 0.09588 11.514 \u0026lt;2e-16\r## compensation_typebank_cheque 1.53888 0.09473 16.245 \u0026lt;2e-16\r## compensation_typecredit_cart 1.89640 0.09586 19.782 \u0026lt;2e-16\r## ## (Intercept) ***\r## compensation_push_pullpush ***\r## compensation_amount_ILS50 ***\r## compensation_amount_ILS75 ***\r## compensation_amount_ILS100 ***\r## compensation_typerefund_next_purchase ## compensation_typecoupon ***\r## compensation_typebank_cheque ***\r## compensation_typecredit_cart ***\r## ---\r## Signif. codes: 0 \u0026#39;***\u0026#39; 0.001 \u0026#39;**\u0026#39; 0.01 \u0026#39;*\u0026#39; 0.05 \u0026#39;.\u0026#39; 0.1 \u0026#39; \u0026#39; 1\r## ## (Dispersion parameter for binomial family taken to be 1)\r## ## Null deviance: 8936.7 on 7019 degrees of freedom\r## Residual deviance: 7295.6 on 7011 degrees of freedom\r## AIC: 7313.6\r## ## Number of Fisher Scoring iterations: 4\rNote how most variables (actually all but compensation_typerefund_next_purchase) are significant and with a positive estimate (i.e., odds ratio \u0026gt; 1). This means means that when a certain variable increases, the probability of choosing the package increases, i.e.:\n\rPassively getting the compensation (“Push”) is better than a required act to get the compensation (“pull”) .\rAny sum of money (50, 75, 100) is better than 25, in an increasing odds ratio.\rMost compensation types (credit card payback, bank cheque, coupon) are significantly better than a complimentary product.\r\rNow comes the interesting part: for example, compare the following three packages. Try to guess which one is more attractive:\n\r\rParameter\rPackage 1\rPackage 2\rPackage 3\r\r\r\rPush/Pull\rPull\rPull\rPush\r\rReturn\rCredit\rRefund\rCoupon\r\rPrice\r25\r75\r25\r\r\r\rIt is not that easy to determine between the three. In this situation there is no single strategy which is superior to the others, we can however plot these three packages with the logistic regression response and standard errors. First let’s put them all in a tibble (I also added the best and worst packages).\npackage_comparison \u0026lt;- tribble(\r~package_name, ~compensation_push_pull, ~compensation_amount_ILS, ~compensation_type,\r\u0026quot;pkg1\u0026quot;, \u0026quot;pull\u0026quot;, 25, \u0026quot;credit_cart\u0026quot;,\r\u0026quot;pkg2\u0026quot;, \u0026quot;pull\u0026quot;, 75, \u0026quot;refund_next_purchase\u0026quot;,\r\u0026quot;pkg3\u0026quot;, \u0026quot;push\u0026quot;, 25, \u0026quot;coupon\u0026quot;,\r\u0026quot;worst\u0026quot;, \u0026quot;pull\u0026quot;, 25, \u0026quot;another_product\u0026quot;,\r\u0026quot;best\u0026quot;, \u0026quot;push\u0026quot;, 100, \u0026quot;credit_cart\u0026quot;\r) %\u0026gt;% mutate(compensation_amount_ILS = factor(compensation_amount_ILS)) # need to convert to factor - which is how it is modeled in the glm.\rpredicted_responses \u0026lt;- predict(conjoint_glm_model, newdata = package_comparison, type = \u0026quot;response\u0026quot;, se.fit = T)\r# lets join these together\rpackage_responses \u0026lt;- package_comparison %\u0026gt;% mutate(fit = predicted_responses$fit,\rse.fit = predicted_responses$se.fit)\rpackage_responses\r## # A tibble: 5 x 6\r## package_name compensation_pu~ compensation_am~ compensation_ty~ fit\r## \u0026lt;chr\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;fct\u0026gt; \u0026lt;chr\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 pkg1 pull 25 credit_cart 0.168 ## 2 pkg2 pull 75 refund_next_pur~ 0.158 ## 3 pkg3 push 25 coupon 0.161 ## 4 worst pull 25 another_product 0.0294\r## 5 best push 100 credit_cart 0.824 ## # ... with 1 more variable: se.fit \u0026lt;dbl\u0026gt;\r# P.S. - excuse the \u0026quot;credit_cart\u0026quot; typo (I build the model that way, only then noticed...)\rggplot(package_responses %\u0026gt;% slice(1:3) , aes(x = package_name, y = fit)) + geom_point() +\rgeom_errorbar(aes(ymin = fit - se.fit, ymax = fit + se.fit)) + ggtitle(\u0026quot;Package comparison (packages 1-3)\u0026quot;, subtitle = \u0026quot;Error bars represent the SE\u0026quot;) + ylab(\u0026quot;Predicted response (glm logit)\u0026quot;) + xlab(\u0026quot;Package name\u0026quot;) +\rscale_y_continuous(labels = scales::percent_format(accuracy = 1))\rggplot(package_responses, aes(x = package_name, y = fit)) + geom_point() +\rgeom_errorbar(aes(ymin = fit - se.fit, ymax = fit + se.fit)) + ggtitle(\u0026quot;Package comparison (including best and worst packages)\u0026quot;, subtitle = \u0026quot;Error bars represent the SE\u0026quot;) + ylab(\u0026quot;Predicted response (glm logit)\u0026quot;) +\rxlab(\u0026quot;Package name\u0026quot;) +\rscale_y_continuous(labels = scales::percent_format(accuracy = 1))\rWe see that the three packages (pkg1, pkg2, and pkg3) are relatively similar, within one standard error from one another. When compared to the worst package they are roughly \\(\\sim8\\) times better (via odds ratio), but the best package is \\(\\sim5\\) times better than packages 1-3.\nOne can use these concepts to illustrate the benefits of each parameter on the different packages, and let the user experience how different features make the packages more or less “attractive”.\nAs an experiment, I prepared a nice little shiny app which lets the user experiment with the different features: build two packages and then compare them. You can checkout the code at the github repo, or check out the live app here.\n\rConclusions\rSurveys are a popular tool used in class actions (at least in Israel). They can be used to estimate the tradeoffs between various types of compensation or settlement, for example with the use of conjoint analysis.\nWith a glm model one can tell the differences of various packages, and the odds ratio is a way to illustrate to decision makers a comparison of various options (and how much “more attractive” is one package over another).\nA shiny app can be a nice way to illustrate the results of a conjoint analysis, and to let the user experiment with how different features make a specific option better or worse than another option.\n\r","date":1549195200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549195200,"objectID":"afd35131d0c5babf2c2f856fccadaf41","permalink":"/post/2019-02-03-class-action-conjoint/","publishdate":"2019-02-03T12:00:00Z","relpermalink":"/post/2019-02-03-class-action-conjoint/","section":"post","summary":"A few days ago I presented at the 9th Israeli class action lawsuit conference. You’re probably asking yourself what would a data scientist do in a room full of lawyers?","tags":["Conjoint analysis","Class actions","shiny"],"title":"Settling class action lawsuits with conjoint analysis and R (+a conjoint shiny app)","type":"post"},{"authors":null,"categories":["R"],"content":"\rWith all the functional programming going on (i.e., purrr::map and the likes), there is at least one thing that I found missing: progress bars. The plyr::do function had a nice looking progress bar open up by default if the operation took more than 2 seconds and had at least two more to go (as per Hadley’s description in Issue#149 in tidyverse/purrr).\nThe issue is still open, for the time of writing these lines, and will probably be solved sometime in the near future as a feature of purrr::map.\nPersonally, I like @cderv’s elegent solution suggested at that same github issue.\nHere is an example implementation for reading multiple files within a directory and combining them into a single tibble while showing a progress bar when reading the files. The file reading is very similar to what was suggested in this post.\nlibrary(purrr)\rlibrary(readr)\rlibrary(dplyr)\r# directory from which to read a bunch of files (the example here uses csv)\rfile_list \u0026lt;- dir(path = \u0026quot;PATH_TO_DIRECTORY\u0026quot;, pattern = \u0026quot;.csv\u0026quot;)\r# define reading function which includes the progress bar updates and printing\rread_with_progress \u0026lt;- function(filename){\rpb$tick()$print()\rdata_read \u0026lt;- read_csv(filename)\r# you can add additional operations on data_read, or # decide on entirely different task that this function should do.\r}\r# create the progress bar with a dplyr function. pb \u0026lt;- progress_estimated(length(file_list))\rres \u0026lt;- file_list %\u0026gt;%\rmap_df(~read_with_progress(.))\rThat’s it. You’re set to go with a cool progress bar which will print out something like this while the operation is carried out:\n|===================================== |80% ~23 s remaining\r","date":1548417600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548417600,"objectID":"afa1fe5368f57b1caff3bb0279096363","permalink":"/post/2019-01-24-purrrying-progress-bars/","publishdate":"2019-01-25T12:00:00Z","relpermalink":"/post/2019-01-24-purrrying-progress-bars/","section":"post","summary":"With all the functional programming going on (i.e., purrr::map and the likes), there is at least one thing that I found missing: progress bars. The plyr::do function had a nice looking progress bar open up by default if the operation took more than 2 seconds and had at least two more to go (as per Hadley’s description in Issue#149 in tidyverse/purrr).","tags":["purrr","progress bars"],"title":"Purrring progress bars (adding a progress bar to `purrr::map`)","type":"post"},{"authors":null,"categories":["R"],"content":"\rFollowing Jenny Bryan’s talk on tidyeval in the last rstudio::conf 2019, I decided to write this short note (mainly as a reminder to myself).\nWhat is tidyeval?\rTidy evaluation, or non standard evaluation, allows us to pass column names between functions. This is the “classic” behaviour of most tidyverse functions. For example, we use:\nlibrary(tidyverse)\rmtcars %\u0026gt;% select(mpg, cyl)\r## mpg cyl\r## Mazda RX4 21.0 6\r## Mazda RX4 Wag 21.0 6\r## Datsun 710 22.8 4\r## Hornet 4 Drive 21.4 6\r## Hornet Sportabout 18.7 8\r## Valiant 18.1 6\r## Duster 360 14.3 8\r## Merc 240D 24.4 4\r## Merc 230 22.8 4\r## Merc 280 19.2 6\r## Merc 280C 17.8 6\r## Merc 450SE 16.4 8\r## Merc 450SL 17.3 8\r## Merc 450SLC 15.2 8\r## Cadillac Fleetwood 10.4 8\r## Lincoln Continental 10.4 8\r## Chrysler Imperial 14.7 8\r## Fiat 128 32.4 4\r## Honda Civic 30.4 4\r## Toyota Corolla 33.9 4\r## Toyota Corona 21.5 4\r## Dodge Challenger 15.5 8\r## AMC Javelin 15.2 8\r## Camaro Z28 13.3 8\r## Pontiac Firebird 19.2 8\r## Fiat X1-9 27.3 4\r## Porsche 914-2 26.0 4\r## Lotus Europa 30.4 4\r## Ford Pantera L 15.8 8\r## Ferrari Dino 19.7 6\r## Maserati Bora 15.0 8\r## Volvo 142E 21.4 4\rThe two variables were selected out of the mtcars data set, and we specified them as names without using any quotation marks. They are symbolic, not characters (although they could also be specified as characters, select is smart enough that way).\nBut assume we want to pass variables “tidy style” between functions which do different operations.\n\rVariation one - a basic example\rWe’ll start simple: a function which has two parameters. The first parameter is a dataset. The second parameters is a grouping variable. All other variables in the data set will have their mean computed using summarize_all.\ntest1 \u0026lt;- function(dataset, groupby_vars){\rgrouping_vars \u0026lt;- enquo(groupby_vars)\rdataset %\u0026gt;% group_by(!! grouping_vars) %\u0026gt;%\rsummarize_all(funs(mean(.))) %\u0026gt;%\rreturn()\r}\rmtcars %\u0026gt;%\rselect(cyl:carb) %\u0026gt;%\rtest1(groupby_vars = cyl)\r## # A tibble: 3 x 10\r## cyl disp hp drat wt qsec vs am gear carb\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 4 105. 82.6 4.07 2.29 19.1 0.909 0.727 4.09 1.55\r## 2 6 183. 122. 3.59 3.12 18.0 0.571 0.429 3.86 3.43\r## 3 8 353. 209. 3.23 4.00 16.8 0 0.143 3.29 3.5\rWe can see that mtcars was grouped by cyl which was passed as a name (not characters). The function test1 took it, then enquo()-ed it, and eventually used it in the tidy chain using !!.\rThe function enquo turns the input into a “quosure”. Then the !! “uses” the quosure to select the proper variable from mtcars.\n\rPassing arguments using ...\rA slightly more complex situation is passing multiple arguments to the function. Assume that this time we want to construct a function which gets one input by which to group by, and what are the variables to be summarized:\ntest2 \u0026lt;- function(dataset, groupby_vars, ...){\rgrouping_vars \u0026lt;- enquo(groupby_vars)\rdataset %\u0026gt;% group_by(!! grouping_vars) %\u0026gt;%\rsummarize_at(vars(...), funs(mean(.))) %\u0026gt;%\rreturn()\r}\rmtcars %\u0026gt;%\rselect(cyl:carb) %\u0026gt;%\rtest2(groupby_vars = cyl, disp:drat)\r## # A tibble: 3 x 4\r## cyl disp hp drat\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 4 105. 82.6 4.07\r## 2 6 183. 122. 3.59\r## 3 8 353. 209. 3.23\rWhat happend is that test2 treats the grouping variable the same way that test1 treated it, but it also passed along the variables disp:drat.\n\rMaximum flexibility - multiple enquo()s\rSometime passing the dots, i.e., ... is not enough.\rFor example, if we want specify behaviour for different columns of the data frame (e.g., compute the mean for some and the std for others). In such cases we need a more flexible version. We can extend the flexibilty of this approach using multiple enqou()s.\ntest3 \u0026lt;- function(dataset, groupby_vars, computemean_vars, computestd_vars){\rgrouping_vars \u0026lt;- enquo(groupby_vars)\rmean_vars \u0026lt;- enquo(computemean_vars)\rstd_vars \u0026lt;- enquo(computestd_vars)\rdataset %\u0026gt;% group_by(!! grouping_vars) %\u0026gt;%\rsummarize_at(vars(!!mean_vars), funs(mean(.))) %\u0026gt;%\rleft_join(dataset %\u0026gt;%\rgroup_by(!! grouping_vars) %\u0026gt;%\rsummarize_at(vars(!!std_vars), funs(sd(.))))\r}\rmtcars %\u0026gt;% test3(groupby_vars = cyl, disp:drat, wt:carb)\r## Joining, by = \u0026quot;cyl\u0026quot;\r## # A tibble: 3 x 10\r## cyl disp hp drat wt qsec vs am gear carb\r## \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt; \u0026lt;dbl\u0026gt;\r## 1 4 105. 82.6 4.07 0.570 1.68 0.302 0.467 0.539 0.522\r## 2 6 183. 122. 3.59 0.356 1.71 0.535 0.535 0.690 1.81 ## 3 8 353. 209. 3.23 0.759 1.20 0 0.363 0.726 1.56\rIn the resulting table, the first column cyl is the grouping variable, columns disp through drat have the mean of the corresponding variables, and columns wt through carb have their standard deviation computed.\n\rAdditional uses of tidy evaluation\rThis evaluation is very useful when building flexible functions, but also when using the ggplot2 syntax within functions, and more so when using Shiny applications, in which input parameters need to go in as grouping or as plotting parameters.\nHowever, this is a topic for a different post.\n\rConclusions\rTidy evaluation empowers you with great tools - it offers a great degree of flexibilty, but it’s a bit tricky to master.\nMy suggestion is that if you’re trying to master tidy evaluation, just think about your use case: which of the three variations presented in this post it resembles too?\nWork your way up - from the simplest version (if it works for you) and up to the complex (but most flexible) version.\n\r","date":1547985600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547985600,"objectID":"bffee4df110f883415ea043910de9482","permalink":"/post/2019-01-20-short-note-about-tidy-eval/","publishdate":"2019-01-20T12:00:00Z","relpermalink":"/post/2019-01-20-short-note-about-tidy-eval/","section":"post","summary":"Following Jenny Bryan’s talk on tidyeval in the last rstudio::conf 2019, I decided to write this short note (mainly as a reminder to myself).\nWhat is tidyeval?\rTidy evaluation, or non standard evaluation, allows us to pass column names between functions.","tags":["tidyeval"],"title":"Short note about tidyeval","type":"post"},{"authors":null,"categories":["R"],"content":"\rFirst, let me start by saying wow!, what a wonderful experience.\nWhen I booked the trip from Israel to Austin, TX, I thought that I’ll see some good content, and learn at the conference (as I in fact did). It was much more enjoyable than I could’ve imagined. In part I guess this can be contributed to the awesome R community. The ease in which you start a conversation with just about anyone in the conference - about R, professional life (or even personal life), that’s great.\nBesides that, visiting Texas (for the first time) was interesting, but for more on that - see venue.\nWorkshop “Shiny Train-the-Trainer”\rThis was a two day workshop. The first day was taught by Greg Wilson, and touched different points of teaching in general, and teaching programming lanugages. The second day was taught by Mine, and zoomed-in on Shiny apps and how to teach building Shiny apps.\nStarting from the theory and building up, Greg was very charismatic. For me, some takeaways from the workshop were:\n\rEach time you start a new course, choose 1-2 things you want to improve/tryout. Don’t try to go “all-in” because then you might miss. Also, make sure that when you do implement new techniques, you don’t fall short on things you were doing so far which were good.\r\rThis is going to be slightly cumbersome (I’m also summarizing this for my own good).\nA few things that helps organize and conduct sessions.\nFigure out who are your learners\rFigure out who are your learners: what are they interested in? what do they already know, and what they don’t know. What is the diversity you’re going to get in the crowd (persona analysis).\nHere’s are examples for different personas we cooked up during the workshop.\nA shiny novice\r\rBackground: Statisticians and Data Scientists from the pharma industry.\rPrior knowledge: Some knowledge but not state of the art.\rMotivation: Want to build shiny apps to share information with other functions in the company.\rHow the course will help them: Able to build simple shiny apps and grow from there.\rSpecial needs: “Think they know but actually don’t”.\r\r\rA shiny expert\r\rBackground: New company moving from a start-up. Biostatistics PhD.\rPrior knowledge: Used R, made apps for paper presentations, done some shiny apps. Looks good but they know that there are stuff that they don’t know. Mix of formal (for the statistics) but a lot of fun learning on their own.\rMotivation: Utilize what they have done, but in the context of the organization, and learn about new and cool things.\rHow the course will help them: Teach them the newest and best things of Shiny, in the context of the company. This is how make it production and enterprise ready.\rSpecial needs: Work from home. Interaction remote. Dog that barks. Online course.\r\r\rA student you expect to encounter at a shiny workshop you teach\r\rBackground: Danny is studying industrial engineering. Undergrad. He is in his third year, and about to finish next year. He likes data science and likes aquiring new programming skills.\rPrior knowledge: Danny has learned some python and some base R, throghout the last few semsters, but he is not fluent in either. Still struggling with some commands in R.\rMotivation: Danny wants to aquire a new tools that will help him next year when he looks for new work, and will help him impress potential employers.\rHow the course will help them: Danny will be able to build apps and use them as showcase while he is looking for work next year. In addition, he will be able to build shiny apps that will help him publish and distribute findings.\rSpecial needs: Danny has a lot of motivation, but is a novice to R and programming in general. He doesn’t have a lot of time for exercise because the semster courses take up a lot of his time, nonetheless, he is willing to invest the time in projects at specific “peaks” in order to advance his skills.\r\r\r\rWrite the learning objectives\rWrite learning objectives which are observable (by the learners) and also measureable. For example:\nThe student will build a shiny app that does…\rThe students will learn and use the renderPlot() function, etc.\r\rHere’s another example for learning objectives of a short introductory 1-hour session:\nThe students will understand the basic elements of a shiny app and describe the difference between ui, server and global.\rThe students will apply the princibles to modify an example reading a file and showing a table with the first 10 lines of the file.\rThe students will learn about and be aware of shiny examples in the gallery.\r\rTo formulate the objectives, one can use bloom’s taxonomy (and the extended version of it that Mine have shown during class).\n\rBuild conceptual maps\rBuild concept maps for each of the topics in the course. I.e., for each class there is a concept map that highlights the topics and the connections between them. Again, referring to the steps in Bloom’s taxonomy as the building blocks of those building blocks. While building the concept maps, remmember that:\n\rRoughly 5-9 items can fit in the short term memory. Consider that when building the concept map. Make sure it’s not too complicated.\rTo make things slightly easier, while teaching, you can use a whiteboard to expand the concept map and show the class where we are on the concept map.\r\r\rWrite the “final exam” and formative assesments\rWrite the final exam, i.e., in the end of the session, what should they be able to answer? This should correspond to the aferomentioned learning objectives.\nGenerate formative assesments (short questions for “check-ins”), that will be used during the lesson. These will help you check if the crowd is with you or lost got lost.\n\rCreate the presentation and learning materials\rFinally, create the learning material around the previous steps. Re-iterate as needed to improve the materials.\n\rSome more useful tools and tips\r\rSticky notes are very useful during programming lessons. This way you can see during the lesson where the class is at. Have 4 colors:\r\rGreen = “everything is fine”\rRed = “need help”\rBlue = “want a break”\rOrange = “want to ask a question”\r\rFor “check-ins” You can use poll everywhere or a similar solution.\rInteractions between students are very useful. Ask a question. Let them talk with one another to get the answer.\r“Baby steps” - use faded examples or incremental examples when teaching. Avoid a “novice blank page” when starting.\rEncourage the students: “what would you type into stackoverflow to find a solution to this problem?”\rNo opting-out. If someone doesn’t know the answer, ask someone else - then go back to that person and ask something else. No one will “fall asleep”, you make sure that everyone are with you. Jump between locations in class (not in the sitting order).\rUse rstudio.cloud when a uniform R environment is desired. We can even start from a flat base instance with all the packages pre-loaded.\r\r\rFeedback\r\rChoose an element from above. Use feedback to understand if it was good or not. Choose an existing thing you do and check that you didn’t lose it either.\rEncourage the students to give feedback to one another by interacting in exercises (can scale up to larger classes).\r\r\rFurther reading\rCheck the online materials of the course. Everything is on a creative commons - BY RStudio - license.\nAll resources for teaching techniques are available at Greg Wilson’s website teachtogether.tech.\nResources specific for Shiny teaching are available at the workshop’s website, including Mine’s teaching notes for 1hr, 2hr, 1/2day, 1day, 2day workshops. See http://teach-shiny.rbind.io.\n\r\rConference Day 1\rHere are some highlights:\n\rJoe Chang’s keynote: lots of tools for testing and profiling shiny apps. Speed improvments for shiny apps using cache (plotCacheRender()). Showd some techniques to make apps much quicker.\rAPI development with R and Tensor flow at T-mobile: A really cool use case for using shiny apps and plumber API. This is an example for scaling up a plumber api for a customer facing app.\rDatabases using R: the latest: Edgar demonstrated how he connects to a google big query database. The big query server does all the computations and the clean (and smaller data) is input into R for continued analysis. Very cool.\rWorking with categorial data in R without loosing your mind: some best practices for working with factors. Advocating forecats (actually much of these I already implement in my work anyhow).\rMelt the clock: tidy time series analysis: a talk about tsibble and fable, the packages which are about to replace the forecast and ts(), in a tidy-er version. Can be installed from github and should make life much easier for time series analysis.\r3D mapping, plotting, and printing with rayshader: an extremely cool package for ploting maps from x-y-z (elevation data). A lot of options, and even includes an export for 3d printing of the models.\rgganimate Live Cookbook: A nice package for animating ggplots. But need to carefully choose when to use and when not to use it…\r\r\rConference Day 2\rGreat RMarkdown session - kind of made me rethink about how I do my work. For me personally a lot of the work envolves power point and word, but from now on, I think I’ll try to do it on RMarkdown. More reproduceable, easier to recreate, or update if needed.\n\rYihui Xie talked about blogdown, bookdown, and more recently pagedown (for academic publications). I also came to know about Radix - a package for Academic style blogs. In the new RStudio (version 1.2 and above, currently in preview), there is an option to export RMarkdown documents into power point presentation. Works seamlessly, just change the yaml at the top:\r\r---\rtitle: \u0026quot;This is a power point presentation\u0026quot;\rauthor: \u0026quot;I\u0026#39;m the author\u0026quot;\rdate: \u0026quot;...\u0026quot;\routput: powerpoint_presentation\r---\r\rThe gt package was presented. A package which is great for generating html or \\(\\LaTeX\\) tables.\rA cool feature of RMarkdown which I didn’t know about is parameters. It enables to creat variants of an RMarkdown document without actually changing the document. For more info see parameterized reports.\rHadley Wikam talked about a new package in development vctrs that is supposed to improve type consistency in R. Here’s an example with factor and c’s default behaviour vs. the vec_c solution in vctrs:\r\rc(factor(\u0026quot;a\u0026quot;), factor(\u0026quot;b\u0026quot;))\r## [1] 1 1\rvctrs::vec_c(factor(\u0026quot;a\u0026quot;), factor(\u0026quot;b\u0026quot;))\r## [1] a b\r## Levels: a b\r\rJenny Bryan talked about lazy evaluation. Finally made some sense to me about when to use enquo() and when to use !!.\rAnother good talk about the ipc package for Shiny apps which require heavy and async computations. That package is able to pass queue and interrupt messages between processes.\rDavid Robinson from DataCamp gave a really inspiring talk about what you can and should do openly (hence me writing this blog post, in the hopes that it’ll be the first of many).\r\r\rVenue\rI landed on Monday and the workshops started on Tuesday, so not too much time to hand around, but following the recommendation of the receptionist in my hotel (which was great, Holiday Inn Austin Town Center), I went to Terry Black’s - an original BBQ resteraunt, which was very good (apparantly also very high on TripAdvisor).\nI also checked out the South of Colorado (SoCo) area - it was nice to walk around and by some small things for the wife and kids.\nParks around the Colorado River - real nice to walk around or jog.\n\rTakeaways\r\rUse more RMarkdown and less powerpoint/word.\rLot of tips on how to improve my R courses (which I should implement).\rShiny is extremly powerful, much more than what I’m using today. Should probably find the time to improve my own Shiny building/programming skills.\rDo a lot more blogging with R and blogdown.\r\r\r","date":1547899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1547899200,"objectID":"6f8148aadf5bfaf4a5f5fb1d8d604df3","permalink":"/post/2019-01-19-rstudio-conf-recap/","publishdate":"2019-01-19T12:00:00Z","relpermalink":"/post/2019-01-19-rstudio-conf-recap/","section":"post","summary":"First, let me start by saying wow!, what a wonderful experience.\nWhen I booked the trip from Israel to Austin, TX, I thought that I’ll see some good content, and learn at the conference (as I in fact did).","tags":["rstudio::conf","conference"],"title":"Recap: what I learned in rstudio::conf2019","type":"post"},{"authors":null,"categories":null,"content":"","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"6f8c6b33263a59bd4e4de690decef4a9","permalink":"/projects/external-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/projects/external-project/","section":"projects","summary":"An example of linking directly to an external project website using `external_link`.","tags":["Demo"],"title":"External Project","type":"projects"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"79cfc0c3ddcfb9255d2520d5f850143e","permalink":"/projects/internal-project/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/projects/internal-project/","section":"projects","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Internal Project","type":"projects"},{"authors":["admin","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\r\r\r\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1441065600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1441065600,"objectID":"966884cc0d8ac9e31fab966c4534e973","permalink":"/publication/journal-article/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/journal-article/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example journal article","type":"publication"},{"authors":["admin","Robert Ford"],"categories":null,"content":"\rClick the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.\r\r\r\rClick the Slides button above to demo Academic\u0026rsquo;s Markdown slides feature.\r\r\rSupplementary notes can be added here, including code and math.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"69425fb10d4db090cfbd46854715582c","permalink":"/publication/conference-paper/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/conference-paper/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":["Source Themes"],"title":"An example conference paper","type":"publication"}]